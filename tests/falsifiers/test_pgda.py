import unittest
import random

import torch

from deep_opt import NeuralNetwork, Property, BoxConstraint
from nn_repair.falsifiers import ProjectedGradientDescentAttack

from properties import property_1

# enable all logging to have details when running the tests
import logging
logging.basicConfig(level=logging.DEBUG)


class TestProjectedGradientDescentAttack(unittest.TestCase):
    def test_acasxu_networks_inverse_property1(self):
        random.seed(2203)
        indices = tuple(zip(
            random.choices(range(1, 6), k=7),
            random.choices(range(1, 10), k=7)
        ))

        networks = []
        for i1, i2 in indices:
            net_file = f"../../deep-opt/resources/acas_xu/nnet/polar_r_t_p_vo_vi/" \
                       f"ACASXU_run2a_{i1}_{i2}_batch_2000.nnet"
            networks.append(NeuralNetwork.load_from_nnet(net_file))

        prop1 = property_1()
        prop = Property(prop1.lower_bounds, prop1.upper_bounds, BoxConstraint(0, '>', 1500),
                        property_name='not ACASXu Ï†1')
        falsifier = ProjectedGradientDescentAttack()

        print(f"Falsifying Networks: {indices}")
        counterexamples_for_each_network = [falsifier.find_counterexample(net, prop) for net in networks]
        print(f"Results: {counterexamples_for_each_network}")

        assert all(counterexamples is not None for counterexamples, _ in counterexamples_for_each_network), \
            "Falsification failed for some network"

        # make sure all returned counterexamples are actually counterexamples
        for network, (counterexamples, _) in zip(networks, counterexamples_for_each_network):
            input_bounds = prop.input_bounds(network)
            for counterexample in counterexamples:
                assert all(lb <= x <= ub for x, (lb, ub) in zip(counterexample.inputs, input_bounds))
                assert not prop.property_satisfied(counterexample.inputs_as_tensor().unsqueeze(0), network)

        # the test below rather tries to ensure the quality of DeepOpt for finding counterexamples
        # the test is not a hard requirement, but it would be desirable that DeepOpt finds counterexamples
        # for at least one network
        assert any(len(counterexamples) > 0 for counterexamples, _ in counterexamples_for_each_network), \
            "No counterexamples found for all network"

    # def test_conv_network_robustness(self):
    #     # this network is trained to classify an all zero input as zero
    #     network = torch.load('../resources/test_conv_network_8x8_inputs.pyt')
    #     prop = Property(
    #         lower_bounds=dict([(i, -0.05) for i in range(64)]),
    #         upper_bounds=dict([(i,  0.05) for i in range(64)]),
    #         output_constraint=ExtremumConstraint(0, '==', 'strict_max'),
    #         property_name='robust at zero'
    #     )
    #     falsifier = FastGradientSignMethod()
    #
    #     counterexamples, status = falsifier.find_counterexample(network, prop)
    #     print(status)
    #     assert counterexamples is not None and len(counterexamples) > 0, \
    #         "No counterexamples found for violated property of trivial network"

    def test_two_neuron_test_net(self):
        """
        Tests that a counterexample is generated by DeepOpt for the two neuron test net.
        """
        network = torch.load('../resources/two_inputs_test_net.pyt')

        prop = Property({0: 0, 1: 0}, {0: 1, 1: 1}, BoxConstraint(0, '<=', 0.5))
        falsifier = ProjectedGradientDescentAttack()

        counterexamples, status = falsifier.find_counterexample(network, prop)
        print(status)
        assert counterexamples is not None and len(counterexamples) > 0, \
            "No counterexamples found for violated property of trivial network"

        # make sure counterexampels are proper counterexamples
        input_bounds = prop.input_bounds(network)
        for counterexample in counterexamples:
            assert all(lb <= x <= ub for x, (lb, ub) in zip(counterexample.inputs, input_bounds))
            assert not prop.property_satisfied(counterexample.inputs_as_tensor().unsqueeze(0), network)
